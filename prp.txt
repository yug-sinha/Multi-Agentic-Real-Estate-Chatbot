(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot$ ls
backend  frontend  venv
(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot$ cd backend
(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot/backend$ ls
__pycache__  agents  config.py  main.py  requirements.txt  utils
(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot/backend$ cd agents
(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot/backend/agents$ ls
__init__.py  __pycache__  property_agent.py  tenancy_agent.py
(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot/backend/agents$ cd ..
(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot/backend$ cd utils
(venv) yug_sinha@SPCINDLPG02VG26:~/Multi-Agentic-Real-Estate-Chatbot/backend/utils$ ls
__init__.py  __pycache__  rag.py


this is the directory of my backend folder

main.py
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import JSONResponse
from agents import property_agent, tenancy_agent
from utils.rag import retrieve_context
import uvicorn
import logging

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

app = FastAPI()

@app.post("/chat")
async def chat_endpoint(query: str = Form(...), file: UploadFile = File(None)):
    """
    Endpoint to handle user queries:
      - If an image file is provided, route the request to the Property Agent.
      - Otherwise, route to the Tenancy Agent.
    """
    logger.info("Received /chat request with query: %s", query)
    additional_context = retrieve_context(query)
    logger.info("Additional context retrieved for query: %s", additional_context)
    
    if file is not None:
        logger.info("File received: %s", file.filename)
        file_bytes = await file.read()
        mime_type = file.content_type
        logger.info("File MIME type: %s", mime_type)
        try:
            response_text = property_agent.process_property_issue(query, file_bytes, additional_context, mime_type)
            logger.info("Property Agent response generated successfully")
            return JSONResponse(content={"agent": "Property Agent", "response": response_text})
        except Exception as e:
            logger.exception("Error in processing property issue")
            raise HTTPException(status_code=500, detail=str(e))
    else:
        logger.info("No file provided. Processing as tenancy query.")
        try:
            response_text = tenancy_agent.process_tenancy_query(query)
            logger.info("Tenancy Agent response generated successfully")
            return JSONResponse(content={"agent": "Tenancy Agent", "response": response_text})
        except Exception as e:
            logger.exception("Error in processing tenancy query")
            raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    logger.info("Starting FastAPI server on http://0.0.0.0:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)

config.py
import os
import logging
from dotenv import load_dotenv
from google import genai

# Configure logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# Load environment variables from .env file
load_dotenv()
logger.info("Environment variables loaded from .env")

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    logger.error("GEMINI_API_KEY not set in environment variables.")
    raise Exception("GEMINI_API_KEY not set in environment variables.")

logger.info("Initializing Gemini client with provided API key.")
client = genai.Client(api_key=API_KEY)
logger.info("Gemini client initialized successfully.")


property_agent.py
import io
import logging
from config import client

logger = logging.getLogger(__name__)

def process_property_issue(query: str, image_bytes: bytes, additional_context: str = "", mime_type: str = "image/jpeg") -> str:
    """
    Processes a property issue query by sending both text and an image to the Gemini model.
    
    Args:
        query (str): The textual component of the user query.
        image_bytes (bytes): Raw bytes of the uploaded image.
        additional_context (str): Optional context from a RAG retrieval process.
        mime_type (str): The MIME type of the image, e.g., "image/jpeg".
        
    Returns:
        str: The response from the Gemini model.
    """
    logger.info("Starting process_property_issue")
    # Wrap image bytes in a stream for uploading.
    image_stream = io.BytesIO(image_bytes)
    try:
        logger.info("Uploading image with MIME type: %s", mime_type)
        # Pass the MIME type when uploading the file.
        uploaded_file = client.files.upload(file=image_stream, config={"mime_type": mime_type})
        logger.info("Image uploaded successfully.")
    except Exception as e:
        logger.exception("Image upload failed")
        raise Exception(f"Image upload failed: {str(e)}")
    
    # Construct the prompt including context and query.
    prompt = (
        f"Context: {additional_context}\n"
        f"User Query: {query}\n"
        "Analyze the provided image for property issues (e.g., water damage, mold, cracks, poor lighting, broken fixtures). "
        "Return a troubleshooting diagnosis and recommendations."
    )
    logger.info("Prompt constructed for property issue: %s", prompt)
    
    # Generate the response using the Gemini model.
    try:
        logger.info("Generating response using Gemini model for property issue")
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[prompt, uploaded_file]
        )
        logger.info("Response generated successfully for property issue")
        return response.text
    except Exception as e:
        logger.exception("Property agent generation failed")
        raise Exception(f"Property agent generation failed: {str(e)}")


tenancy_agent.py
import logging
from config import client
from utils.rag import retrieve_context

logger = logging.getLogger(__name__)

# Define the prompt template for tenancy FAQ queries using RAG.
TENANCY_PROMPT_TEMPLATE = (
    "You are a legal and property management expert specializing in tenancy laws and rental agreements.\n"
    "Retrieved Context: {context}\n"
    "User Query: {query}\n"
    "Provide a comprehensive, legally informed answer including any necessary legal conditions and practical advice. "
    "If relevant, ask if more location-specific information is needed."
)

def process_tenancy_query(query: str) -> str:
    """
    Processes tenancy-related queries using a Retrieval-Augmented Generation approach.
    
    Args:
        query (str): The tenancy-related question from the user.
        
    Returns:
        str: The generated answer from the tenancy agent.
    """
    logger.info("Starting process_tenancy_query with query: %s", query)
    try:
        context = retrieve_context(query)
        logger.info("Retrieved context for tenancy query: %s", context)
    except Exception as e:
        logger.exception("Failed to retrieve context")
        raise Exception(f"Context retrieval failed: {str(e)}")
    
    # Fill the prompt template with the retrieved context.
    prompt = TENANCY_PROMPT_TEMPLATE.format(context=context, query=query)
    logger.info("Constructed prompt for tenancy query: %s", prompt)
    
    try:
        logger.info("Generating response using Gemini model for tenancy query")
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[prompt]
        )
        logger.info("Tenancy response generated successfully")
        return response.text
    except Exception as e:
        logger.exception("Tenancy agent generation failed")
        raise Exception(f"Tenancy agent generation failed: {str(e)}")

rag.py
import logging

logger = logging.getLogger(__name__)

def retrieve_context(query: str) -> str:
    """
    Simulates retrieval of additional context for a given query.
    
    Args:
        query (str): The user query.
        
    Returns:
        str: Retrieved context relevant to the tenancy query.
    """
    logger.info("Retrieving context for query: %s", query)
    context = f"Relevant tenancy information based on the query: '{query}'."
    logger.info("Context retrieved: %s", context)
    return context



now understand the whole codebase and help mme build a proper interactive chatbot UI for this application, we will be using  nextjs, and i want it to be exactly like a chatbot, like how ChatGPT UI looks like, how gemini and other AI chatbots UI looks like, i also want to see the agent that returned the response as that is also getting returned here, help me build the UI frontend for this, give me all the commands and codes for this


we will be using nextjs for this and make the middleware setup such that it works for production deployments too, undertsand all the codes and help me build my frontend directory 